<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Adaptive and safe reinforcement learning algorithm for resource allocation in 
         dynamic wireless networks.">
  <meta name="keywords" content="META RL, Spectrum Allocation, Wireless Networks">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="./static/js/slideshow.js"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://oluwaseyiwater.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://wirelessoptim.github.io">
            WirelessOptim
          </a>
          <a class="navbar-item" href="https://oluwaseyiwater.github.io/qppgrl.github.io/">
            QuantumRL
          </a>
          <a class="navbar-item" href="https://oluwaseyiwater.github.io/meta-rl/">
            MetaRL
          </a>
          <a class="navbar-item" href="https://causalwireless.github.io">
            CausalWireless
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Meta-Reinforcement Learning 
            for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://oluwaseyiwater.github.io">Oluwaseyi Giwa</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Tobi Awodunmila</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ahmd-mohsin.github.io">Muhammad Ahmed Mohsin</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://ahsanbilal7.github.io/">Ahsan Bilal</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=at4MvYMAAAAJ&hl=en">Muhammad Ali Jamshed</a><sup>4</sup>,
            </span>
  
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>African Institute for Mathematical Sciences,</span>
            <span class="author-block"><sup>2</sup>Stanford University</span>
            <span class="author-block"><sup>3</sup>University of Oklahoma</span>
            <span class="author-block"><sup>4</sup>University of Glasgow</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/OluwaseyiWater/meta_learnedRL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">

  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="./static/images/framework.jpg">
    </div>
  </div>

  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="./static/images/archi.jpg">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Meta</span> reinforcement learning (RL) ensures faster adaptation
         of RL agent in an environment by learning the initial policy and quickly adapting. In a wireless environment, meta RL 
         captures the dynamic nature of
          components which is suitable for safe exploration of agent.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. 
            However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety 
            risks associated with unguided exploration, which can cause severe network interference.
          </p>
          <p>
          To address these challenges, we propose a meta-learning framework that enables agents to learn
           a robust initial policy and rapidly adapt to new wireless scenarios with minimal data.
            We implement three meta-learning architectures&mdash; model-agnostic meta-learning (MAML), 
            recurrent neural network (RNN), and an attention-enhanced RNN&mdash; and evaluate them 
            against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline,
             in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a
              clear performance gap. The attention-based meta-learning agent reaches a peak mean 
              network throughput of
           \(\approx 48\) Mbps, while the PPO baseline decreased drastically to \(10\) Mbps.
          </p>
          <p>
            Furthermore, our method reduces SINR and latency violations by more than \(50\%\) compared to PPO.
             It also shows quick adaptation, with a fairness index \(\geq 0.7\), showing better resource
              allocation. This work proves that meta-learning is a very effective and safer 
            option for intelligent control in complex wireless systems.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

  

    <!-- Results -->

    <div class="slideshow-container">
      <h2 class="title is-3">Results</h2>

      <div class="mySlides fade">
        <div class="numbertext">1 / 5</div>
        <img src="./static/images/combined_fairness.jpg">
        <div class="text">Fairness Index.</div>
      </div>

      <div class="mySlides fade">
        <div class="numbertext">2 / 5</div>
        <img src="./static/images/combined_latency.jpg">
        <div class="text">Mean Latency Violations.</div>
      </div>

      <div class="mySlides fade">
        <div class="numbertext">3 / 5</div>
        <img src="./static/images/combined_rewards.jpg">
        <div class="text">Mean Episodic Reward.</div>
      </div>

      <div class="mySlides fade">
        <div class="numbertext">4 / 5</div>
        <img src="./static/images/combined_sinr.jpg">
        <div class="text">Mean SINR Violations.</div>
      </div>

      <div class="mySlides fade">
        <div class="numbertext">5 / 5</div>
        <img src="./static/images/combined_throughput.jpg">
        <div class="text">Network Throughput.</div>
      </div>

    </div>
    <br>

    <div style="text-align: center">
      <span class="dot"></span>
      <span class="dot"></span>
      <span class="dot"></span>
      <span class="dot"></span>
      <span class="dot"></span>
    </div>
    



    

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Works</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was very useful for the completion of this work.
          </p>
          <p>
            <a href="https://proceedings.mlr.press/v70/finn17a.html">Model-Agnostic Meta-Learning for Fast Adaptation of
               Deep Networks</a> was the basis of our architecture.
          </p>
          <p>
            <a href="https://doi.org/10.1609/aaai.v38i11.29136">Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning</a>
            is another excellent literature.
          </p>
          <!-- <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{oluwaseyi2025,
  author    = {Oluwaseyi, Giwa and Tobi, Awodunmila and Muhammad, Ahmed Mohsin and Ahsan, Bilal and Muhammad, Ali Jamshed},
  title     = {Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks},
  journal   = {IEEE Wireless Communications Letters},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/OluwaseyiWater" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
